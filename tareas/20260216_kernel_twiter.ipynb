{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8a5b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID       Entity Sentiment  \\\n",
      "0   2401  Borderlands  Positive   \n",
      "1   2401  Borderlands  Positive   \n",
      "2   2401  Borderlands  Positive   \n",
      "3   2401  Borderlands  Positive   \n",
      "4   2401  Borderlands  Positive   \n",
      "..   ...          ...       ...   \n",
      "95  2416  Borderlands   Neutral   \n",
      "96  2417  Borderlands  Negative   \n",
      "97  2417  Borderlands  Negative   \n",
      "98  2417  Borderlands  Negative   \n",
      "99  2417  Borderlands  Negative   \n",
      "\n",
      "                                                Tweet  \n",
      "0   im getting on borderlands and i will murder yo...  \n",
      "1   I am coming to the borders and I will kill you...  \n",
      "2   im getting on borderlands and i will kill you ...  \n",
      "3   im coming on borderlands and i will murder you...  \n",
      "4   im getting on borderlands 2 and i will murder ...  \n",
      "..                                                ...  \n",
      "95  I hate that this easy horrible modifier event ...  \n",
      "96  Grounded almost looked pretty cool even despit...  \n",
      "97  Grounded looked cool despite the borderline un...  \n",
      "98  Grosskreutz looked pretty cool, even despite t...  \n",
      "99  Grounded almost looked pretty cool here despit...  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../datasets/twitter_training.csv', header=None, names=['ID', 'Entity', 'Sentiment', 'Tweet'])\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f705df",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "Quiero que primero analices el prompt que te compartiré, y me digas si le falta algo en estructura KERNEL, no quiero que tenga indicaciones basura y sea óptimo.\n",
    "\n",
    "\n",
    "\"\n",
    "De acuerdo a los datos del dataframe df, quiero lo siguiente:\n",
    "Eres un experto en data science en identificación de patrones. Y debes analizar los tweets que te comparta. Debes clasificar el texto de acuerdo a 3 categorías: Positivo, Negativo y Neutral.\n",
    "El formato de respuesta debe ser en Json con llave id y sentimiento, solamente me deberás dar la clasificación sin explicación.\n",
    "Si solamente son caracteres especiales o no tiene sentido, clasificaclo como irrelevante.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb67af",
   "metadata": {},
   "source": [
    "## Respuesta\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "K - Knowledge (Contexto)\n",
    "Tienes un DataFrame llamado 'df' con las columnas: ID, Entity, Sentiment, Tweet.\n",
    "Tu tarea es reclasificar la columna 'Tweet' basándote únicamente en el contenido del texto.\n",
    "\n",
    "E - Expectations (Expectativas)\n",
    "Clasifica cada tweet en UNA de estas categorías:\n",
    "- Positive\n",
    "- Negative  \n",
    "- Neutral\n",
    "- Irrelevant (si solo contiene caracteres especiales o texto sin sentido)\n",
    "\n",
    "R - Role (Rol)\n",
    "Actúa como experto en análisis de sentimientos con experiencia en procesamiento de lenguaje natural y clasificación de texto en redes sociales.\n",
    "\n",
    "N - Narrowing (Acotación)\n",
    "Reglas estrictas:\n",
    "1. Analiza SOLO el contenido de la columna 'Tweet'\n",
    "2. Ignora la columna 'Sentiment' existente (es para validación posterior)\n",
    "3. NO proporciones explicaciones ni razonamientos\n",
    "4. Clasifica tweets vacíos o con solo símbolos como \"Irrelevant\"\n",
    "\n",
    "E - Expectations (Formato de salida)\n",
    "Para cada tweet, devuelve UN objeto JSON con esta estructura exacta:\n",
    "{\"id\": <valor_de_columna_ID>, \"sentiment\": \"<categoría>\"}\n",
    "\n",
    "Ejemplo de salida esperada:\n",
    "{\"id\": 2401, \"sentiment\": \"Positive\"}\n",
    "{\"id\": 2402, \"sentiment\": \"Irrelevant\"}\n",
    "\n",
    "L - Limitations (Limitaciones)\n",
    "- Procesa los tweets de uno en uno cuando se te solicite\n",
    "- Usa exactamente los nombres de categorías especificados (case-sensitive)\n",
    "- NO agregues campos adicionales al JSON\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b261c",
   "metadata": {},
   "source": [
    "## Response\n",
    "\n",
    "Voy a crear una lista de tareas para rastrear el trabajo (qué voy a hacer y en qué orden), luego clasificaré cada tweet y devolveré los JSONs solicitados. Resultado: lista creada y luego produciré las salidas JSON para cada tweet.\n",
    "\n",
    "Created 7 todos\n",
    "\n",
    "Progreso: lista de tareas creada y requisitos confirmados. Ahora devuelvo los JSONs con la clasificación (sin explicaciones), uno por línea.\n",
    "\n",
    "{\"id\": 4433, \"sentiment\": \"Negative\"}\n",
    "{\"id\": 6273, \"sentiment\": \"Negative\"}\n",
    "{\"id\": 7925, \"sentiment\": \"Positive\"}\n",
    "{\"id\": 11332, \"sentiment\": \"Positive\"}\n",
    "{\"id\": 1107, \"sentiment\": \"Positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacc983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eebcefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
